{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import json\n",
    "from arcgis.features import FeatureLayer\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Call to Louisville Open Data. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Steps      | Description | Notes     |\n",
    "| :---        |    :----   |          :--- |\n",
    "| 1. Open Data API call      | API call for restaurant inspection scores | Works   |\n",
    "| 2. Clean   | Remove un-needed data        | drop cols and sort data. Also ned to only keep the most recent scores      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://services1.arcgis.com/79kfd2K6fskCAkyg/arcgis/rest/services/FoodServiceData/FeatureServer/0'\n",
    "\n",
    "batch_size = 1000  # Number of records to retrieve per batch\n",
    "offset = 0  # Initial offset value\n",
    "data_list = []\n",
    "# â€‹Create the feature layer object\n",
    "feature_layer = FeatureLayer(url)\n",
    "\n",
    "while True:\n",
    "    # Query the feature layer with pagination\n",
    "    query_result = feature_layer.query(where='1=1', out_fields='*', return_geometry=False, result_offset=offset, result_record_count=batch_size)\n",
    "    \n",
    "    # Retrieve the features from the query result\n",
    "    features = query_result.features\n",
    "    \n",
    "    # Process the data for the current batch\n",
    "    for feature in features:\n",
    "        data_list.append(feature.attributes)\n",
    "    \n",
    "    # Break the loop if the response is empty or the desired number of records is reached\n",
    "    if len(features) == 0 or len(data_list) >= 1000:\n",
    "        break\n",
    "    \n",
    "    # Increment the offset by the batch size\n",
    "    offset += batch_size\n",
    "# Create a DataFrame from the data list\n",
    "df = pd.DataFrame(data_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the data comes in correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drops the extra cols we dont need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_drop = ['EstablishmentID', 'InspectionID', 'PlaceName', 'Address2', 'TypeDescription', 'NameSearch', 'Intersection']\n",
    "df.drop(cols_drop, axis=1, inplace=True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting InspectionDate to date time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['InspectionDate'] = pd.to_datetime(df['InspectionDate'])\n",
    "# sorting inspection dates\n",
    "df.sort_values('InspectionDate', ascending=False, inplace=True)\n",
    "# dropping duplicate rest based on its first occurrence\n",
    "df.drop_duplicates(subset='EstablishmentName', keep='first', inplace=True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.value_counts('EstablishmentName')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='score', ascending=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_json('../json_files/health.json')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp API "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports my API key for yelp. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from akeys import api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key\n",
    "endpoint = \"businesses/search\"\n",
    "url = f\"https://api.yelp.com/v3/{endpoint}\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "params = {\n",
    "    \"term\": \"restaurants\",\n",
    "    \"location\": \"Louisville, KY\",\n",
    "    \"limit\": 50  # Set the desired limit per request (maximum is 50)\n",
    "}\n",
    "\n",
    "restaurant_data = []  # List to store the extracted data\n",
    "\n",
    "offset = 0  # Initial offset value\n",
    "results_per_request = params[\"limit\"]  # Results per request (50)\n",
    "total_results = float(\"inf\")  # Initialize total_results to an arbitrary high value\n",
    "\n",
    "while offset < total_results:\n",
    "    params[\"offset\"] = offset  # Set the offset parameter\n",
    "    \n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error: {response.status_code} - {response.text}\")\n",
    "        break\n",
    "    \n",
    "    data = response.json()\n",
    "\n",
    "    if offset == 0:\n",
    "        total_results = data[\"total\"]\n",
    "    \n",
    "    businesses = data[\"businesses\"]\n",
    "    \n",
    "    for business in businesses:\n",
    "        name = business.get(\"name\")\n",
    "        rating = business.get(\"rating\")\n",
    "        review_count = business.get(\"review_count\")\n",
    "        price = business.get(\"price\")\n",
    "        address = \", \".join(business.get(\"location\", {}).get(\"display_address\", []))\n",
    "        restaurant_data.append({\n",
    "            \"Name\": name,\n",
    "            \"Rating\": rating,\n",
    "            \"Review Count\": review_count,\n",
    "            \"Price\": price,\n",
    "            \"Address\": address\n",
    "        })\n",
    "    offset += results_per_request  \n",
    "    time.sleep(2)  \n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df2 = pd.DataFrame(restaurant_data)\n",
    "\n",
    "# Print the DataFrame\n",
    "df2.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.sort_values(by=\"Rating\", ascending=True)\n",
    "df2 = df2.loc[df[\"Rating\"] != 0.0]\n",
    "df2 = df2.reset_index(drop=True)\n",
    "df2['Rating'] = (df2['Rating']*20).astype(int)\n",
    "df2.head()\n",
    "df2.to_json('../json_files/yelp.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Address'] = df2['Address'].str.split(',').str[0]\n",
    "df2['Rating'] = (df2['Rating']*20).astype(int)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Address'] = df['Address'].str.lower().str.strip()\n",
    "df2['Address'] = df2['Address'].str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = df.merge(df2, on='Address', how='left')\n",
    "merged_df = merged_df.sort_values('Rating', ascending=True)\n",
    "merged_df = merged_df[['EstablishmentName', 'Address', 'score', 'Rating', 'Review Count']]\n",
    "merged_df.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
